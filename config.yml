# dataset
# dataset name, param1, param2
dataset: 20newsgroups

# embeddings
embedding: glove,50
# embedding aggregation method to document-level representations
# - avg: average word embeddings to a single doc vector
# - pad,NUM,filter: force NUM words / embeddings per document, padding / pruning where necessary 
# NUM words are selected by filter:
# first: just get the first NUM words
# freq: get the NUM words that are most frequent in the dataset
# aggregation: pad,10,first
aggregation: avg

# semantic resource settings
# resource,population_strategy,weighting_strategy,pruning_strategy

semantic_resource: wordnet
# the form of semantic information to use
# frequencies or tfidf
semantic_weights: freq
# drop synsets with dataset-wise freq less than this threshold
#semantic_freq_threshold: 15
# how the semantic information is combined with the textual one
# enrichment: concat
# enrichment: concat
# pos, embedding-centroid
disambiguation: pos

# learning model
# dnn or lstm
# learner: lstm,128,10
learner: mlp,128,4

train:
  epochs: 50
  folds: 3
  early_stopping_patience: -1

batch_size: 20
# log_level: debug
log_level: info

#parallelization: 10
#parallelization: 4

options:
  data_limit: 100

results_folder: "results"
serialization_dir: "serialization"
